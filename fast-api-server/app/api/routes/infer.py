from fastapi import APIRouter, HTTPException
from app.schemas.request import InferenceRequest
from app.schemas.response import InferenceResponse
from app.services.preprocess import preprocess_image
from app.services.inference import run_inference
from app.services.postprocess import postprocess_result

router = APIRouter()

@router.post("/infer", response_model=InferenceResponse)
def run_ai_inference(request: InferenceRequest):
    try:
        image_tensor = preprocess_image(request.image_url)
        result = run_inference(request.crop_type, image_tensor)

        postprocessed = postprocess_result(
            result["label"],
            result["confidence"]
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))

    return InferenceResponse(
        scan_id=request.scan_id,
        disease=result["label"],
        confidence=result["confidence"],
        severity="unknown",
        recommendation="Further analysis required"
        if result["label"] == "needs_expert_review"
        else "Diagnosis generated by AI"
    )
